# === LLM CONFIGURATION ===
LLM_MODEL=gemini:gemini-flash-lite-latest
LLM_API_KEY=your-key-here

# Only required for Ollama or LocalAI
# LLM_BASE_URL=http://localhost:11434

# === TOOL CONFIGURATION ===
# TMDB: Use "API Read Access Token"
MMCP_PLUGIN_TMDB_API_KEY=your_tmdb_key_here
